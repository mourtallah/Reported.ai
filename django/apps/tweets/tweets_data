{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f54317f",
   "metadata": {},
   "source": [
    "Tweet topics extraction\n",
    "\n",
    "\n",
    "In this file trying to fetch tweets data and filtering out all unncecessary parameter from the tweets.\n",
    "importing the important libraray, tweepy is used to get data from twitter API\n",
    "this recommender system will be able to recommend videos to us, based on top news topics and based on combination of features.\n",
    "First, we load the models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87711209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import required libraries\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import csv\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import re \n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from matplotlib.pyplot import xlabel,ylabel,title\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import tweepy\n",
    "from tweepy import API\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38af4e29",
   "metadata": {},
   "source": [
    "1. Gather the data\n",
    " import data from twitter api\n",
    "authentication details to connect with twittet api to fetch data.\n",
    "For this problem I decided to retrieve the dataset based on top twitter topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8292f894",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"\"\n",
    "api_secret = \"\"\n",
    "access_token = \"\"\n",
    "access_token_secret= \"\"\n",
    "username= \"\"\n",
    "screen_name=username\n",
    "\n",
    "auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "user=api.verify_credentials()\n",
    "from googleapiclient.discovery import build\n",
    "youtube = build('youtube', 'v3', developerKey='AIzaSyBfoGn0960ZupAD7YiIdwfRe1MDbdg9F_U')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c633a1d1",
   "metadata": {},
   "source": [
    "first content-based recommender will have a goal of recommending tweets which have a similar plot to a selected tweet topics.\n",
    "searching th tweets based on particular keywords and extracting the tweets data, like count tweet created data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4382dd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweets         object\n",
       "likes           int64\n",
       "createddate    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = []\n",
    "likes = []\n",
    "createdate = []\n",
    "try:\n",
    "    os.remove('tweets1data.csv')\n",
    "    #print \"File deleted\"\n",
    "except:\n",
    "    #print \"File was not present already\"\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "csvFile = open('tweets1data.csv', 'w')\n",
    "csvWriter = csv.writer(csvFile)\n",
    "search_words = [\"stock market\",\"wildfire\",\"Immigration\",\"cryptocurrency\",\"covid\",\n",
    "                \"artificial intelligence\",\"inflation\",\"lake mead\"]\n",
    "date_since = \"2018-11-16\"\n",
    "for search_word in search_words:\n",
    "    for i in tweepy.Cursor(api.search_tweets,\n",
    "              q=search_word).items(5):\n",
    "     \n",
    "        tweets.append(i.text)\n",
    "        likes.append(i.favorite_count)\n",
    "        twcreatedate=i.created_at.date()\n",
    "        createdate.append(twcreatedate)\n",
    "        csvWriter.writerow([i.text.encode('utf-8', errors='ignore'),i.created_at,i.favorite_count])\n",
    "\n",
    "csvFile.close()\n",
    "df = pd.DataFrame({'tweets':tweets,'likes':likes,'createddate':createdate})\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684ef3d",
   "metadata": {},
   "source": [
    "printing all th tweets data frmaes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6ce9277",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>createddate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do you think the market will react to this...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Day 43:\\nAsking #DGISPR about Stock Market and...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actively turn a profit. I wanna put money into...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@angelbeech59 @GOP UnderBiden:\\nRecord crime\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @sapuge: If you are an Investor, Stock Brok...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @CphilpottCraig: Timelapse from the first n...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @CphilpottCraig: Timelapse from the first n...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>news 27 July 2022 Machine learning model uses ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @YtZlashy: AWP | Wildfire MW ($100) #CSGOGi...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://t.co/WNC4t6j6zh</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RT @Stephane_Ravier: 🎥 Le meilleur moyen de dé...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RT @naimamfaddel: Bravo au #policier Rida pour...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@bbcworldservice As opposed to British cities ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RT @FoxNews: IMMIGRATION CRISIS: Washington, D...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@mouts59 @Olivierqtl @ChiabertoMarine @Zemmour...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I have been consistently warning about cryptoc...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RT @RichQuack: The Quack Tales 🦆🚀\\n👇👇\\n#RichQU...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Digital Currencys are unstopable !!!  #ripple ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BORED IS GOOD , but LAZY is BETTER !\\nGot TACO...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>⚡A Soccer Team In Argentina Signs First Crypto...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RT @gerdantes: Null-Covid-Politik - Sackgasse ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RT @ProficientMinds: I’m just tired. My 20s be...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RT @kuu331108: 『世界保健機関が警告：天然痘ワクチンはCovidワクチン接種者...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>@samanthamarika1 No.  Because that didn’t happ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>@Flash784 @Berly2910 @kwquinn @mitchgarber htt...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>RT @DrEliDavid: Why is everyone excited about ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RT @kritarthmittal: Artificial Intelligence ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>RT @robmarkcole: New discovery: Mapping Roads ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>RT @Ravisutanjani: For every 1 Million people,...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>RT @samuel_wong_: How to make Artificial Intel...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweets  likes createddate\n",
       "0   How do you think the market will react to this...      0  2022-07-31\n",
       "1   Day 43:\\nAsking #DGISPR about Stock Market and...      0  2022-07-31\n",
       "2   actively turn a profit. I wanna put money into...      0  2022-07-31\n",
       "3   @angelbeech59 @GOP UnderBiden:\\nRecord crime\\n...      0  2022-07-31\n",
       "4   RT @sapuge: If you are an Investor, Stock Brok...      0  2022-07-31\n",
       "5   RT @CphilpottCraig: Timelapse from the first n...      0  2022-07-31\n",
       "6   RT @CphilpottCraig: Timelapse from the first n...      0  2022-07-31\n",
       "7   news 27 July 2022 Machine learning model uses ...      0  2022-07-31\n",
       "8   RT @YtZlashy: AWP | Wildfire MW ($100) #CSGOGi...      0  2022-07-31\n",
       "9                             https://t.co/WNC4t6j6zh      0  2022-07-31\n",
       "10  RT @Stephane_Ravier: 🎥 Le meilleur moyen de dé...      0  2022-07-31\n",
       "11  RT @naimamfaddel: Bravo au #policier Rida pour...      0  2022-07-31\n",
       "12  @bbcworldservice As opposed to British cities ...      0  2022-07-31\n",
       "13  RT @FoxNews: IMMIGRATION CRISIS: Washington, D...      0  2022-07-31\n",
       "14  @mouts59 @Olivierqtl @ChiabertoMarine @Zemmour...      0  2022-07-31\n",
       "15  I have been consistently warning about cryptoc...      0  2022-07-31\n",
       "16  RT @RichQuack: The Quack Tales 🦆🚀\\n👇👇\\n#RichQU...      0  2022-07-31\n",
       "17  Digital Currencys are unstopable !!!  #ripple ...      0  2022-07-31\n",
       "18  BORED IS GOOD , but LAZY is BETTER !\\nGot TACO...      0  2022-07-31\n",
       "19  ⚡A Soccer Team In Argentina Signs First Crypto...      0  2022-07-31\n",
       "20  RT @gerdantes: Null-Covid-Politik - Sackgasse ...      0  2022-07-31\n",
       "21  RT @ProficientMinds: I’m just tired. My 20s be...      0  2022-07-31\n",
       "22  RT @kuu331108: 『世界保健機関が警告：天然痘ワクチンはCovidワクチン接種者...      0  2022-07-31\n",
       "23  @samanthamarika1 No.  Because that didn’t happ...      0  2022-07-31\n",
       "24  @Flash784 @Berly2910 @kwquinn @mitchgarber htt...      0  2022-07-31\n",
       "25  RT @DrEliDavid: Why is everyone excited about ...      0  2022-07-31\n",
       "26  RT @kritarthmittal: Artificial Intelligence ba...      0  2022-07-31\n",
       "27  RT @robmarkcole: New discovery: Mapping Roads ...      0  2022-07-31\n",
       "28  RT @Ravisutanjani: For every 1 Million people,...      0  2022-07-31\n",
       "29  RT @samuel_wong_: How to make Artificial Intel...      0  2022-07-31"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73709f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[~df.tweets.str.contains(\"RT\")]\n",
    "df=df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab3b5bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9aecc868",
   "metadata": {},
   "source": [
    "this function removes all @ symbolic sentencs in tweets data,removes the tags,remove capital letter which are not necessary. filtering out tweets will help to decrease the input data. increase the proccessing speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a34c5d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>likes</th>\n",
       "      <th>createddate</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How do you think the market will react to this...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>How do you think the market will react to this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Day 43:\\nAsking #DGISPR about Stock Market and...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>Day 43:\\nAsking DGISPR about Stock Market and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>actively turn a profit. I wanna put money into...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>actively turn a profit. I wanna put money into...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@angelbeech59 @GOP UnderBiden:\\nRecord crime\\n...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>UnderBiden:\\nRecord crime\\nRecord inflation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>news 27 July 2022 Machine learning model uses ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>news 27 July 2022 Machine learning model uses ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  likes createddate  \\\n",
       "0  How do you think the market will react to this...      0  2022-07-31   \n",
       "1  Day 43:\\nAsking #DGISPR about Stock Market and...      0  2022-07-31   \n",
       "2  actively turn a profit. I wanna put money into...      0  2022-07-31   \n",
       "3  @angelbeech59 @GOP UnderBiden:\\nRecord crime\\n...      0  2022-07-31   \n",
       "4  news 27 July 2022 Machine learning model uses ...      0  2022-07-31   \n",
       "\n",
       "                                          clean_text  \n",
       "0  How do you think the market will react to this...  \n",
       "1  Day 43:\\nAsking DGISPR about Stock Market and ...  \n",
       "2  actively turn a profit. I wanna put money into...  \n",
       "3    UnderBiden:\\nRecord crime\\nRecord inflation ...  \n",
       "4  news 27 July 2022 Machine learning model uses ...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_text(text):\n",
    "  text = re.sub(r'@[A-Za-z0-9]+','',text) #removes @mentions\n",
    "  text = re.sub(r'#','',text) #removes # tags\n",
    "  text = re.sub(r'\\\\n','',text) #removes # tags\n",
    "  text = re.sub(r'RT[\\s]+','',text) #removes RT\n",
    "  text = re.sub(r'https?:\\/\\/\\S+','',text) #removes urls\n",
    "\n",
    "  return text\n",
    "df['clean_text']=df['tweets'].apply(clean_text)\n",
    "\n",
    "#display clean text\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcba95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44f17436",
   "metadata": {},
   "source": [
    "TF-IDF approach\n",
    "A statistical measure that evaluates how relevant a word is to a document in a collection of documents.\n",
    "TF-IDF of a word in a document which is part of a larger corpus of documents is a combination of two values. One is term frequency (TF), which measures how frequently the word occurs in the document some of the words, such as “the” and “is”, occur frequently in all documents and we want to downscale the importance of such words. This is accomplished by multiplying TF with the inverse document frequency.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3795d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(stop_words='english')\n",
      "  (0, 75)\t0.3207281872170537\n",
      "  (0, 68)\t0.10833281675001315\n",
      "  (0, 156)\t0.3207281872170537\n",
      "  (0, 108)\t0.3207281872170537\n",
      "  (0, 85)\t0.3207281872170537\n",
      "  (0, 107)\t0.3207281872170537\n",
      "  (0, 133)\t0.3207281872170537\n",
      "  (0, 15)\t0.3207281872170537\n",
      "  (0, 119)\t0.3207281872170537\n",
      "  (0, 92)\t0.24992973039470687\n",
      "  (0, 138)\t0.3207281872170537\n",
      "  (1, 8)\t0.21528168417285432\n",
      "  (1, 10)\t0.21528168417285432\n",
      "  (1, 132)\t0.21528168417285432\n",
      "  (1, 64)\t0.21528168417285432\n",
      "  (1, 118)\t0.21528168417285432\n",
      "  (1, 47)\t0.43056336834570863\n",
      "  (1, 134)\t0.3749663160532417\n",
      "  (1, 43)\t0.43056336834570863\n",
      "  (1, 14)\t0.21528168417285432\n",
      "  (1, 2)\t0.21528168417285432\n",
      "  (1, 40)\t0.21528168417285432\n",
      "  (1, 68)\t0.07271600118311008\n",
      "  (1, 92)\t0.33551957968587914\n",
      "  (2, 3)\t0.3125278777227077\n",
      "  :\t:\n",
      "  (14, 53)\t0.29321943322250515\n",
      "  (14, 93)\t0.2553570943415305\n",
      "  (14, 81)\t0.2553570943415305\n",
      "  (14, 39)\t0.29321943322250515\n",
      "  (14, 66)\t0.29321943322250515\n",
      "  (14, 143)\t0.29321943322250515\n",
      "  (14, 30)\t0.29321943322250515\n",
      "  (14, 26)\t0.29321943322250515\n",
      "  (14, 110)\t0.29321943322250515\n",
      "  (14, 68)\t0.09904114572050106\n",
      "  (15, 4)\t0.2708552334529944\n",
      "  (15, 54)\t0.2708552334529944\n",
      "  (15, 87)\t0.2708552334529944\n",
      "  (15, 70)\t0.2708552334529944\n",
      "  (15, 113)\t0.2708552334529944\n",
      "  (15, 91)\t0.2708552334529944\n",
      "  (15, 88)\t0.2708552334529944\n",
      "  (15, 135)\t0.2708552334529944\n",
      "  (15, 145)\t0.2708552334529944\n",
      "  (15, 74)\t0.2708552334529944\n",
      "  (15, 67)\t0.2708552334529944\n",
      "  (15, 139)\t0.2708552334529944\n",
      "  (15, 93)\t0.23588070081722337\n",
      "  (15, 81)\t0.23588070081722337\n",
      "  (15, 68)\t0.09148715810122308\n"
     ]
    }
   ],
   "source": [
    "tf_idf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "tf_idf_matrix = tf_idf.fit_transform(df['tweets']);\n",
    "print(tf_idf)\n",
    "print(tf_idf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a21c5b",
   "metadata": {},
   "source": [
    "Cosine similarity\n",
    "By applying the definition of similarity, this will be in fact equal to 1 if the two vectors are identical, \n",
    "and it will be 0 if the two are orthogonal. In other words, the similarity is a number bounded between \n",
    "0 and 1 that tells us how much the two vectors are similar. \n",
    "Now that we have numerical vectors, representing each tweets plot description, here i tried can compute similarity of tweets content\n",
    "by calculating their pair-wise cosine similarities\n",
    "and storing them in cosine similarity matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11c6d539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.09173385 0.07230372 0.00705877 0.00973995 0.03466753\n",
      "  0.         0.00884517 0.01138578 0.01052504 0.00884517 0.01152132\n",
      "  0.01371903 0.01618075 0.01072941 0.00991106]\n",
      " [0.09173385 1.         0.19144386 0.00473804 0.00653772 0.02326981\n",
      "  0.         0.00593712 0.00764245 0.0070647  0.00593712 0.00773343\n",
      "  0.00920859 0.01086097 0.00720188 0.00665258]\n",
      " [0.07230372 0.19144386 1.         0.00687829 0.00949092 0.03378116\n",
      "  0.         0.00861902 0.01109467 0.07843327 0.00861902 0.01122674\n",
      "  0.01336826 0.01576705 0.01045508 0.00965766]\n",
      " [0.00705877 0.00473804 0.00687829 1.         0.00585821 0.02085123\n",
      "  0.         0.00532004 0.00684812 0.00633042 0.00532004 0.0529951\n",
      "  0.00825148 0.00973212 0.00645334 0.00596113]\n",
      " [0.00973995 0.00653772 0.00949092 0.00585821 1.         0.02877129\n",
      "  0.         0.00734078 0.00944929 0.00873495 0.00734078 0.00956177\n",
      "  0.0113857  0.01342874 0.00890455 0.00822539]\n",
      " [0.03466753 0.02326981 0.03378116 0.02085123 0.02877129 1.\n",
      "  0.         0.02612816 0.033633   0.03109042 0.02612816 0.03403336\n",
      "  0.04052529 0.04779711 0.03169411 0.02927676]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  1.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.00884517 0.00593712 0.00861902 0.00532004 0.00734078 0.02612816\n",
      "  0.         1.         0.00858121 0.00793249 0.00666641 0.00868336\n",
      "  0.01033973 0.01219508 0.00808652 0.00746975]\n",
      " [0.01138578 0.00764245 0.01109467 0.00684812 0.00944929 0.033633\n",
      "  0.         0.00858121 1.         0.11890663 0.00858121 0.13016204\n",
      "  0.01330963 0.0156979  0.01040923 0.0096153 ]\n",
      " [0.01052504 0.0070647  0.07843327 0.00633042 0.00873495 0.03109042\n",
      "  0.         0.00793249 0.11890663 1.         0.00793249 0.12032209\n",
      "  0.01230345 0.01451117 0.00962231 0.00888841]\n",
      " [0.00884517 0.00593712 0.00861902 0.00532004 0.00734078 0.02612816\n",
      "  0.         0.00666641 0.00858121 0.00793249 1.         0.00868336\n",
      "  0.01033973 0.01219508 0.00808652 0.00746975]\n",
      " [0.01152132 0.00773343 0.01122674 0.0529951  0.00956177 0.03403336\n",
      "  0.         0.00868336 0.13016204 0.12032209 0.00868336 1.\n",
      "  0.01346807 0.01588476 0.01053314 0.00972976]\n",
      " [0.01371903 0.00920859 0.01336826 0.00825148 0.0113857  0.04052529\n",
      "  0.         0.01033973 0.01330963 0.01230345 0.01033973 0.01346807\n",
      "  1.         0.01891481 0.01254235 0.01158573]\n",
      " [0.01618075 0.01086097 0.01576705 0.00973212 0.01342874 0.04779711\n",
      "  0.         0.01219508 0.0156979  0.01451117 0.01219508 0.01588476\n",
      "  0.01891481 1.         0.01479294 0.01366466]\n",
      " [0.01072941 0.00720188 0.01045508 0.00645334 0.00890455 0.03169411\n",
      "  0.         0.00808652 0.01040923 0.00962231 0.00808652 0.01053314\n",
      "  0.01254235 0.01479294 1.         0.12952861]\n",
      " [0.00991106 0.00665258 0.00965766 0.00596113 0.00822539 0.02927676\n",
      "  0.         0.00746975 0.0096153  0.00888841 0.00746975 0.00972976\n",
      "  0.01158573 0.01366466 0.12952861 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity_matrix = cosine_similarity(tf_idf_matrix, tf_idf_matrix)\n",
    "print(cosine_similarity_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b72804",
   "metadata": {},
   "source": [
    "The function first determines the index of the input tweets, retrieves the similarities of tweets with selected tweet topic, sorts them and returns the content of the tweets with the highest similarity to the selected tweet topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d97eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_from_title(df,tweets):\n",
    "    rThe function first determines the index of the input movie, retrieves the similarities of movies with selected movie, sorts them and returns the titles of movies with the highest similarity to the selected movie.\n",
    "\n",
    "# function that returns the title of the movie from its index\n",
    "\n",
    "def title_from_index(df,index):\n",
    "\n",
    "    return df[df.index==index].tweets.values[0]\n",
    "\n",
    "\n",
    "# generating recommendations for given title\n",
    "\n",
    "def recommendations( tweets, df,cosine_similarity_matrix,number_of_recommendations):\n",
    "\n",
    "    index = index_from_title(df,tweets)\n",
    "\n",
    "    similarity_scores = list(enumerate(cosine_similarity_matrix[index]))\n",
    "\n",
    "    similarity_scores_sorted = sorted(similarity_scores, key=lambda x: x[1], reverse=True)\n",
    "    recommendations_indices = [t[0] for t in similarity_scores_sorted[1:(number_of_recommendations+1)]]\n",
    "\n",
    "    return df['tweets'].iloc[recommendations_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffebae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations('stock', df, cosine_similarity_matrix, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d7b08f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d342cdee",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrecommendations\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstock\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcosine_similarity_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mrecommendations\u001b[0;34m(tweets, df, cosine_similarity_matrix, number_of_recommendations)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecommendations\u001b[39m( tweets, df,cosine_similarity_matrix,number_of_recommendations):\n\u001b[0;32m---> 16\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43mindex_from_title\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtweets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     similarity_scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28menumerate\u001b[39m(cosine_similarity_matrix[index]))\n\u001b[1;32m     20\u001b[0m     similarity_scores_sorted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(similarity_scores, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m1\u001b[39m], reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36mindex_from_title\u001b[0;34m(df, tweets)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mindex_from_title\u001b[39m(df,tweets):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtweets\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mtweets\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20bbb68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8912b4ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef0f619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
